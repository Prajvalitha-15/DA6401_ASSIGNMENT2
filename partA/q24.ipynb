{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11461364,"sourceType":"datasetVersion","datasetId":7181802}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient() \n\npersonal_key_for_api = user_secrets.get_secret(\"wandb-key\")\n\n! wandb login $personal_key_for_api","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os \nimport io\nfrom PIL import Image\nfrom torch.utils.data import DataLoader \nfrom torchvision import datasets, transforms\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport wandb\nfrom torch.optim.lr_scheduler import OneCycleLR\nimport copy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config = {\n    \"name\": \"CNN's hyperparameter search\",\n    \"metric\": {\n        \"name\": \"validationAccuracy\",\n        \"goal\": \"maximize\"\n    },\n    \"method\": \"random\",\n    \"parameters\": {\n        \"filters\": {\n            \"values\": [32, 64]\n            },\n        \"activationFunction\": {\n            \"values\": ['ReLU', 'GELU', 'SiLU']\n            },\n        \"filterOrganisation\": {\n            \"values\": ['same', 'half']\n            },\n        \"batchNormalisation\": {\n            \"values\": ['yes', 'no']\n            },\n        \"dropout\": {\n            \"values\": [0.2, 0.3]\n            }\n    }\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, \n                 filters=32,\n                 activationFunction='ReLU',\n                 filterOrganisation='same', \n                 batchNormalisation='yes',\n                 dropout=0.2,\n                 num_classes=10\n                 ):\n        super(CNN, self).__init__()\n\n        # Select activation function\n        activations = {\n            'ReLU': nn.ReLU(),\n            'GELU': nn.GELU(),\n            'SiLU': nn.SiLU()        \n        }\n        self.activation = activations.get(activationFunction, nn.ReLU())\n\n        # Setup convolutional layers\n        filter_list = [filters]\n        for i in range(4):\n            if filterOrganisation == 'half':\n                filters = max(8, filters // 2)\n            filter_list.append(filters)\n\n        layers = []\n        in_channels = 3  # RGB image\n\n        for out_channels in filter_list:\n            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n            if batchNormalisation == 'yes':\n                layers.append(nn.BatchNorm2d(out_channels))\n            layers.append(self.activation)\n            layers.append(nn.MaxPool2d(2))  # Reduce H, W by half\n            if dropout > 0:\n                layers.append(nn.Dropout(dropout))\n            in_channels = out_channels\n\n        self.conv_layers = nn.Sequential(*layers)\n\n        # After 5 MaxPool layers on 224x224: 224 -> 112 -> 56 -> 28 -> 14 -> 7\n        self.flattened_size = filter_list[-1] * 7 * 7\n\n        self.classifier = nn.Sequential(\n            nn.Linear(self.flattened_size, 256),\n            self.activation,\n            nn.Dropout(dropout),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = x.view(x.size(0), -1)  # Flatten\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)  # Normalize RGB to [-1, 1]\n])\n\ntrain_dataset = datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/train', transform=transform)\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/val', transform=transform)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import Subset, random_split\nimport random\n\n# Define the percentage or number of samples you want\nnum_train_samples = 6000\ntrain_indices = random.sample(range(len(train_dataset)), num_train_samples)\ntrain_subset = Subset(train_dataset, train_indices)\n\nval_size = 1000\ntrain_size = 5000\ntrain_subset, val_subset = random_split(train_subset, [train_size, val_size])\n\nnum_test_samples = 1000\ntest_indices = random.sample(range(len(test_dataset)), num_test_samples)\ntest_subset = Subset(test_dataset, test_indices)\n\n# Create data loaders\ntrain_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\ntest_loader = DataLoader(test_subset, batch_size=64, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(filters, activationFunction, filterOrganisation, batchNormalisation, dropout) :\n\n    model = CNN(filters = filters,\n                activationFunction = activationFunction ,\n                filterOrganisation = filterOrganisation ,\n                batchNormalisation = batchNormalisation,\n                dropout = dropout).to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    for epoch in range(42): \n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n        train_acc = 100. * correct / total\n\n        wandb.log({\n                \"epoch\" : epoch, \n                \"train_acc\" : train_acc\n            })\n\n        print('Epoch -', epoch, '- Train accuracy -', train_acc)\n    \n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    val_acc = 100. * correct / total\n\n    return train_acc, val_acc, model   ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sweep_hyperparameters() :\n    \n    default = {\n        'filters' : 32, \n        'activationFunction' : 'ReLU', \n        'filterOrganisation' : 'same', \n        'batchNormalisation' : 'yes', \n        'dropout' : 0.2\n    }\n\n    wandb.init(project= \"assignment2\", entity= \"da6401-assignments\")\n    wandb.init(config= default)\n\n    config = wandb.config \n\n    filters = config.filters  \n    activationFunction = config.activationFunction \n    filterOrganisation = config.filterOrganisation \n    batchNormalisation = config.batchNormalisation \n    dropout = config.dropout \n\n    wandb.run.name = '#'.join(map(str,(\n        filters, activationFunction, filterOrganisation, batchNormalisation, dropout\n    )))\n\n    trainacc, valacc, model = train(filters, activationFunction, filterOrganisation, batchNormalisation, dropout)\n\n    wandb.log({\n        'validationAccuracy' : valacc, \n        'trainAccuracy' : trainacc\n    })\n\n    wandb.run.save()\n\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweepId = wandb.sweep(sweep_config, entity=\"da6401-assignments\", project=\"assignment2\")\nwandb.agent(sweepId, sweep_hyperparameters, count=48)\nwandb.finish()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"api = wandb.Api()\nruns = api.runs(\"da6401-assignments/assignment2\")\nbest_run = max(runs, key=lambda run: run.summary.get(\"validationAccuracy\", float(\"inf\")))\n\nprint(f\"Best run name: {best_run.name}. \\nValidation Accuracy: {best_run.summary.get('validationAccuracy')}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_acc, val_acc, model = train(\n    filters = 64, \n    activationFunction = 'ReLU', \n    filterOrganisation = 'half', \n    batchNormalisation = 'yes', \n    dropout = 0.3\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\ntest_acc = 100. * correct / total","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, labels = next(iter(test_loader))\nimages = images[:30]  \nlabels = labels[:30]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images = images.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_class = sorted(os.listdir('/kaggle/input/inaturalist/inaturalist_12K/train'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Move tensors to CPU for plotting\nimages = images.cpu()\npreds = preds.cpu()\nlabels = labels.cpu()\n\n# Create grid\nfig, axes = plt.subplots(10, 3, figsize=(10, 30))\naxes = axes.flatten()\n\nfor i in range(30):\n    img = images[i]\n    img = img.permute(1, 2, 0).numpy()\n\n    axes[i].imshow(img)\n    pred_label = label_class[preds[i].item()]\n    true_label = label_class[labels[i].item()]\n    \n    # Optional: color title based on correctness\n    color = \"green\" if preds[i] == labels[i] else \"red\"\n    axes[i].set_title(f'Pred: {pred_label}\\nAct: {true_label}', color=color)\n    axes[i].axis('off')\n\nplt.tight_layout()\n\n# Save figure to a buffer instead of showing\nbuf = io.BytesIO()\nplt.savefig(buf, format='png')\nbuf.seek(0)\nplt.close(fig)\n\n# Convert buffer to PIL Image and log to wandb\nwandb.log({\"Predictions Grid\": wandb.Image(Image.open(buf))})","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}